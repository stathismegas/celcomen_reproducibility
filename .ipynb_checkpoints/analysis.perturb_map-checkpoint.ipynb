{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da84fe-4091-4125-9429-6313e3cc393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# set figure parameters\n",
    "sc.settings.set_figure_params(dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5f77c-c5f4-4e47-8a5f-46ddaca26566",
   "metadata": {},
   "source": [
    "## define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ea4e3-16e4-4267-922a-166115e08ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to gather positions\n",
    "def get_pos(n_x, n_y):\n",
    "    # create the hex lattice\n",
    "    xs = np.array([np.arange(0, n_x) + 0.5 if idx % 2 == 0 else np.arange(0, n_x) for idx in range(n_y)])\n",
    "    # derive the y-step given a distance of one\n",
    "    y_step = np.sqrt(1**2+0.5**2)\n",
    "    ys = np.array([[y_step * idy] * n_x for idy in range(n_y)])\n",
    "    # define the positions\n",
    "    pos = np.vstack([xs.flatten(), ys.flatten()]).T\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f1b73-1376-4f19-98c8-c4c5b3b705e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to derive the gex from the sphex\n",
    "def calc_gex(sphex):\n",
    "    \"\"\"\n",
    "    Calculates the gene expression matrix from the spherical\n",
    "    \"\"\"\n",
    "    # setup the gex\n",
    "    n_genes = sphex.shape[1]+1\n",
    "    gex = torch.from_numpy(np.zeros((sphex.shape[0], n_genes)).astype('float32'))\n",
    "    # compute the gex\n",
    "    for idx in range(n_genes):\n",
    "        if idx == n_genes-1:\n",
    "            gex[:,idx] = torch.sin(sphex[:,idx-1])\n",
    "        else:\n",
    "            gex[:,idx] = torch.cos(sphex[:,idx])\n",
    "        for idx_ in range(idx):\n",
    "            gex[:,idx] *= torch.sin(sphex[:,idx_])\n",
    "    return gex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b8f70-e063-43c2-a4b3-6589249f2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "# define the number of neighbors (six for visium)\n",
    "n_neighbors = 6\n",
    "# define the simcomen class\n",
    "class simcomen(torch.nn.Module):\n",
    "    # define initialization function\n",
    "    def __init__(self, input_dim, output_dim, n_neighbors, seed=0):\n",
    "        super(simcomen, self).__init__()\n",
    "        # define the seed\n",
    "        torch.manual_seed(seed)\n",
    "        # set up the graph convolution\n",
    "        self.conv1 = GCNConv(input_dim, output_dim, add_self_loops=False)\n",
    "        # set up the linear layer for intracellular gene regulation\n",
    "        self.lin = torch.nn.Linear(input_dim, output_dim)\n",
    "        # define the neighbors\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # define a tracking variable for the gene expression x matrix\n",
    "        self.sphex = None\n",
    "        self.gex = None\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g(self, g2g):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g matrix to be a specified interaction matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.conv1.lin.weight = torch.nn.Parameter(g2g, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(n_genes).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g_intra(self, g2g_intra):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g intracellular matrix to be a specified matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.lin.weight = torch.nn.Parameter(g2g_intra, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.lin.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g_intra)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the sphex matrix\n",
    "    def set_sphex(self, sphex):\n",
    "        \"\"\"\n",
    "        Artifically sets the current sphex matrix\n",
    "        \"\"\"\n",
    "        self.sphex = torch.nn.Parameter(sphex, requires_grad=True)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction or training,\n",
    "        convolutes the input by the expected interactions and returns log(Z_mft)\n",
    "        \"\"\"\n",
    "        # compute the gex\n",
    "        self.gex = calc_gex(self.sphex)\n",
    "        # compute the message\n",
    "        msg = self.conv1(self.gex, edge_index)\n",
    "        # compute intracellular message\n",
    "        msg_intra = self.lin(self.gex)\n",
    "        # compute the log z mft\n",
    "        log_z_mft = self.log_Z_mft(edge_index, batch)\n",
    "        return msg, msg_intra, log_z_mft\n",
    "\n",
    "    # define approximation function\n",
    "    def log_Z_mft(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Mean Field Theory approximation to the partition function. Assumptions used are:\n",
    "        - expression of values of genes are close to their mean values over the visium slide\n",
    "        - \\sum_b g_{a,b} m^b >0 \\forall a, where m is the mean gene expression and g is the gene-gene\n",
    "          interaction matrix.\n",
    "        \"\"\"\n",
    "        # retrieve number of spots\n",
    "        num_spots = self.gex.shape[0]\n",
    "        # calculate mean gene expression        \n",
    "        mean_genes = torch.mean(self.gex, axis=0).reshape(-1,1)  # the mean should be per connected graph\n",
    "        # calculate the norm of the sum of mean genes\n",
    "        g = torch.norm(torch.mm( self.n_neighbors*self.conv1.lin.weight + 2*self.lin.weight, mean_genes))   # maybe needs to change to g = torch.norm(torch.mm(mean_genes, self.conv1.lin.weight))\n",
    "        # calculate the contribution for mean values        \n",
    "        z_mean = - num_spots  * torch.mm(torch.mm(torch.t(mean_genes), self.lin.weight + 0.5 * self.n_neighbors * self.conv1.lin.weight),  mean_genes)\n",
    "        # calculate the contribution gene interactions\n",
    "        z_interaction = self.z_interaction(num_spots=num_spots, g=g)\n",
    "        # add the two contributions        \n",
    "        log_z_mft = z_mean + z_interaction\n",
    "        return log_z_mft\n",
    "\n",
    "    def z_interaction(self, num_spots, g):\n",
    "        \"\"\"\n",
    "        Avoid exploding exponentials by returning an approximate interaction term for the partition function.\n",
    "        \"\"\"\n",
    "        if g>20:\n",
    "            z_interaction = num_spots * ( g - torch.log( g) )\n",
    "        else:\n",
    "            z_interaction = num_spots * torch.log((torch.exp( g) - torch.exp(- g))/( g))\n",
    "        return z_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e7c2d-efff-4ef2-bf6c-5d9baeb0839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the celcomen class\n",
    "class celcomen(torch.nn.Module):\n",
    "    # define initialization function\n",
    "    def __init__(self, input_dim, output_dim, n_neighbors, seed=0):\n",
    "        super(celcomen, self).__init__()\n",
    "        # define the seed\n",
    "        torch.manual_seed(seed)\n",
    "        # set up the graph convolution\n",
    "        self.conv1 = GCNConv(input_dim, output_dim, add_self_loops=False)\n",
    "        # set up the linear layer for intracellular gene regulation\n",
    "        self.lin = torch.nn.Linear(input_dim, output_dim)\n",
    "        # define the neighbors\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # define a tracking variable for the gene expression x matrix\n",
    "        self.gex = None\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g(self, g2g):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g matrix to be a specified interaction matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.conv1.lin.weight = torch.nn.Parameter(g2g, requires_grad=True)\n",
    "        # and then set the bias as all zeros\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g_intra(self, g2g_intra):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g intracellular matrix to be a specified matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.lin.weight = torch.nn.Parameter(g2g_intra, requires_grad=True)\n",
    "        # and then set the bias as all zeros\n",
    "        self.lin.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g_intra)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the sphex matrix\n",
    "    def set_gex(self, gex):\n",
    "        \"\"\"\n",
    "        Artifically sets the current sphex matrix\n",
    "        \"\"\"\n",
    "        self.gex = torch.nn.Parameter(gex, requires_grad=False)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction or training,\n",
    "        convolutes the input by the expected interactions and returns log(Z_mft)\n",
    "        \"\"\"\n",
    "        # compute the message\n",
    "        msg = self.conv1(self.gex, edge_index)\n",
    "        # compute intracellular message\n",
    "        msg_intra = self.lin(self.gex)\n",
    "        # compute the log z mft\n",
    "        log_z_mft = self.log_Z_mft(edge_index, batch)\n",
    "        return msg, msg_intra, log_z_mft\n",
    "\n",
    "    # define approximation function\n",
    "    def log_Z_mft(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Mean Field Theory approximation to the partition function. Assumptions used are:\n",
    "        - expression of values of genes are close to their mean values over the visium slide\n",
    "        - \\sum_b g_{a,b} m^b >0 \\forall a, where m is the mean gene expression and g is the gene-gene\n",
    "          interaction matrix.\n",
    "        \"\"\"\n",
    "        # retrieve number of spots\n",
    "        num_spots = self.gex.shape[0]\n",
    "        # calculate mean gene expression        \n",
    "        mean_genes = torch.mean(self.gex, axis=0).reshape(-1,1)  # the mean should be per connected graph\n",
    "        # calculate the norm of the sum of mean genes\n",
    "        g = torch.norm(torch.mm( self.n_neighbors*self.conv1.lin.weight + 2*self.lin.weight, mean_genes))   # maybe needs to change to g = torch.norm(torch.mm(mean_genes, self.conv1.lin.weight))\n",
    "        # calculate the contribution for mean values        \n",
    "        z_mean = - num_spots  * torch.mm(torch.mm(torch.t(mean_genes), self.lin.weight + 0.5 * self.n_neighbors * self.conv1.lin.weight),  mean_genes)\n",
    "        # calculate the contribution gene interactions\n",
    "        z_interaction = self.z_interaction(num_spots=num_spots, g=g)\n",
    "        # add the two contributions        \n",
    "        log_z_mft = z_mean + z_interaction\n",
    "        return log_z_mft\n",
    "\n",
    "    def z_interaction(self, num_spots, g):\n",
    "        \"\"\"\n",
    "        Avoid exploding exponentials by returning an approximate interaction term for the partition function.\n",
    "        \"\"\"\n",
    "        if g>20:\n",
    "            z_interaction = num_spots * ( g - torch.log( g) )\n",
    "        else:\n",
    "            z_interaction = num_spots * torch.log((torch.exp( g) - torch.exp(- g))/( g))\n",
    "        return z_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e18f8e-efde-403d-831e-84bb4084d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to normalize the g2g\n",
    "def normalize_g2g(g2g):\n",
    "    \"\"\"\n",
    "    Addresses any small fluctuations in symmetrical weights\n",
    "    \"\"\"\n",
    "    # symmetrize the values\n",
    "    g2g = (g2g + g2g.T) / 2\n",
    "    # force them to be between 0-1\n",
    "    g2g[g2g < 0] = 0\n",
    "    g2g[g2g > 1] = 1\n",
    "    # force the central line to be 1\n",
    "    for idx in range(len(g2g)):\n",
    "        g2g[idx, idx] = 1\n",
    "    return g2g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422df9b-ff4f-454f-9b2d-ba07b6605e56",
   "metadata": {},
   "source": [
    "## read in perturb-map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60896119-e874-4da5-88a7-e92eb18277dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "prefix = 'GSM5808054_KP_1'\n",
    "a = sc.read_visium(f'/home/dchen2/LITERATURE/GSE193460_RAW/{prefix}')\n",
    "a.var_names_make_unique()\n",
    "# remove off tissue spots\n",
    "off_tissue = pd.read_csv(f'/home/dchen2/LITERATURE/GSE193460_RAW/{prefix}/off_tissue.csv.gz', index_col=0)\n",
    "a = a[~a.obs.index.isin(off_tissue.index)]\n",
    "# load in spot annotations\n",
    "spot_anno = pd.read_csv(f'/home/dchen2/LITERATURE/GSE193460_RAW/{prefix}/spot_annotation.csv.gz', index_col=0)\n",
    "a.obs = spot_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fb97c-0515-4618-8d31-0f941347149b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# confirm annotations were successfully transferred over\n",
    "a.obs['leiden_clusters'] = a.obs['leiden_clusters'].dropna().astype(int).astype(str)\n",
    "sc.pl.spatial(a, color=['kmeans','leiden_clusters','phenotypes'], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ab753-959e-4699-9167-5aac6664fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "# retrieve the space\n",
    "idxs = a.obs['leiden_clusters'].dropna().index\n",
    "coords = a[idxs].obsm['spatial']\n",
    "coords_dist = pd.DataFrame(squareform(pdist(coords)), index=idxs, columns=idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d05037-664d-4100-a781-e30a06dda10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram to confirm dual peaks at 0, 50, and 100\n",
    "plt.hist(coords_dist.values.flatten()[coords_dist.values.flatten() < 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c03db9-0ab4-4f01-97e1-10f1a1f433c0",
   "metadata": {},
   "source": [
    "## define lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb15840-9be9-49f4-88cb-471811351b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# retrieve the indexes of the perturbed\n",
    "idxs_perturbed = a.obs.index[a.obs['phenotypes'].str.startswith('Jak2') | a.obs['phenotypes'].str.startswith('Tgfbr2')]\n",
    "# derive the subsets\n",
    "mask1 = (a.obsm['spatial'][:, 0] > 2100) & (a.obsm['spatial'][:, 0] < 2900) & \\\n",
    "(a.obsm['spatial'][:, 1] > 1500) & (a.obsm['spatial'][:, 1] < 1900) & \\\n",
    "(a.obs['phenotypes'].str.startswith('KP_')) & (a.obs.index.isin(coords_dist.index[(coords_dist[idxs_perturbed] > 100).all(1)]))\n",
    "sc.pl.spatial(a[mask1], color=['phenotypes'], s=10)\n",
    "mask2 = (a.obsm['spatial'][:, 0] > 2700) & (a.obsm['spatial'][:, 0] < 3000) & \\\n",
    "(a.obsm['spatial'][:, 1] > 2500) & (a.obsm['spatial'][:, 1] < 3000) & \\\n",
    "(a.obs['phenotypes'].str.startswith('KP_')) & (a.obs.index.isin(coords_dist.index[(coords_dist[idxs_perturbed] > 100).all(1)]))\n",
    "sc.pl.spatial(a[mask2], color=['phenotypes'], s=10)\n",
    "mask3 = (a.obsm['spatial'][:, 0] > 1600) & (a.obsm['spatial'][:, 0] < 2100) & \\\n",
    "(a.obsm['spatial'][:, 1] > 1500) & (a.obsm['spatial'][:, 1] < 1900) & \\\n",
    "(a.obs['phenotypes'].str.startswith('KP_')) & (a.obs.index.isin(coords_dist.index[(coords_dist[idxs_perturbed] > 100).all(1)]))\n",
    "sc.pl.spatial(a[mask3], color=['phenotypes'], s=10)\n",
    "mask4 = (a.obsm['spatial'][:, 0] > 800) & (a.obsm['spatial'][:, 0] < 1050) & \\\n",
    "(a.obsm['spatial'][:, 1] > 1400) & (a.obsm['spatial'][:, 1] < 1550) & \\\n",
    "(a.obs['phenotypes'].str.startswith('KP_')) & (a.obs.index.isin(coords_dist.index[(coords_dist[idxs_perturbed] > 100).all(1)]))\n",
    "sc.pl.spatial(a[mask4], color=['phenotypes'], s=10)\n",
    "mask5 = (a.obsm['spatial'][:, 0] > 500) & (a.obsm['spatial'][:, 0] < 1400) & \\\n",
    "(a.obsm['spatial'][:, 1] > 1560) & (a.obsm['spatial'][:, 1] < 2500) & \\\n",
    "(a.obs['phenotypes'].str.startswith('KP_')) & (a.obs.index.isin(coords_dist.index[(coords_dist[idxs_perturbed] > 100).all(1)]))\n",
    "sc.pl.spatial(a[mask5], color=['phenotypes'], s=10)\n",
    "# subset for these representative subgraphs\n",
    "a1 = a[mask1].copy()\n",
    "a2 = a[mask2].copy()\n",
    "a3 = a[mask3].copy()\n",
    "a4 = a[mask4].copy()\n",
    "a5 = a[mask5].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a5e92-7f67-4bcd-bb04-bfb992bf487d",
   "metadata": {},
   "source": [
    "## retrieve highly variable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ef1eb-999d-4732-b73a-c187e7a266b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# derive highly variable genes for all of these and ensure that TGFBR2 is included\n",
    "a_objs = {'a1':a1, 'a2':a2, 'a3':a3, 'a4':a4, 'a5':a5}\n",
    "hvgs = []\n",
    "for name, a_obj in a_objs.items():\n",
    "    # extract irrelevant columns\n",
    "    cols = ['WPRE', 'mCherry_Nter', 'linker', 'Procode']\n",
    "    a_obj.obs[cols] = sc.get.obs_df(a_obj, keys=cols)\n",
    "    a_obj = a_obj[:, ~a_obj.var.index.isin(cols)].copy()\n",
    "    # normalize the data\n",
    "    sc.pp.normalize_total(a_obj, target_sum=1e6)\n",
    "    sc.pp.log1p(a_obj)\n",
    "    # derive highly variable genes\n",
    "    sc.pp.highly_variable_genes(a_obj, flavor='seurat', min_mean=0.5, max_mean=7.5, min_disp=0.5)\n",
    "    print(name, a_obj.var['highly_variable'].sum(), a_obj.var.loc['Tgfbr2', 'highly_variable'], a_obj.var.loc['Jak2', 'highly_variable'])\n",
    "    hvgs.extend(a_obj.var.index[a_obj.var['highly_variable']])\n",
    "    a_objs[name] = a_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e960c8-0fc5-4b63-a3d6-991315bb26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find common highly variable genes (need to be in at least 75% of samples)\n",
    "hvg_list = pd.Series(hvgs).value_counts()\n",
    "hvg_list = hvg_list.index[hvg_list >= (len(a_objs) * 0.75)].tolist()\n",
    "len(hvg_list), 'Tgfbr2' in hvg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113bf946-830f-4b24-a351-76112a9b4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add TGFBR2 and JAK2 to the list\n",
    "hvg_list.extend(['Tgfbr2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b3fc5-0225-4984-a629-0dc2c06134bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a gene subset for testing\n",
    "genes = hvg_list\n",
    "# create a tracking variable of the datas for the dataloader\n",
    "data_list = []\n",
    "# loop through each sample\n",
    "for name, a_obj in a_objs.items():\n",
    "    # retrieve positions from the data\n",
    "    pos = torch.from_numpy(a_obj.obsm['spatial'])\n",
    "    # convert the gene expression data to numpy\n",
    "    x = torch.from_numpy(a_obj[:, genes].X.todense())\n",
    "    # sphere normalize the data (just in case)\n",
    "    norm_factor = torch.pow(x, 2).sum(1).reshape(-1,1)\n",
    "    assert (norm_factor > 0).all()\n",
    "    x = torch.div(x, norm_factor)\n",
    "    y = torch.Tensor([0])  # here we will store GT value\n",
    "    # find the edges via kneighbors, not including self because we are considering intercellular\n",
    "    edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "    edge_index = torch.from_numpy(np.array(np.where(edge_index)))\n",
    "    # create the final torch geometric graph dataframe\n",
    "    data = torch_geometric.data.Data(x=x, pos=pos, y=y, edge_index=edge_index)\n",
    "    data.validate(raise_on_error=True)  # performs basic checks on the graph\n",
    "    # store the data in the data list tracker\n",
    "    data_list.append(data)\n",
    "    print(data)\n",
    "# convert into a data loader\n",
    "data_loader = DataLoader(data_list, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32315695-091f-4923-8572-f139ca3c0166",
   "metadata": {},
   "source": [
    "## learn wild type gene-gene links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ea84d-5a01-4821-9e0b-9f822f2bdfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameters of the model\n",
    "n_genes = len(genes)\n",
    "learning_rate = 1e0\n",
    "zmft_scalar = 1e-1\n",
    "seed = 0\n",
    "epochs = 100\n",
    "# instantiate the model, input and output will be the same\n",
    "model_rev = celcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "# now perform the simulation\n",
    "np.random.seed(seed)\n",
    "# artifically set the g2g matrix\n",
    "input_g2g = np.random.uniform(size=(n_genes, n_genes)).astype('float32')\n",
    "input_g2g = normalize_g2g((input_g2g + input_g2g.T) / 2)\n",
    "model_rev.set_g2g(torch.from_numpy(input_g2g))\n",
    "model_rev.set_g2g_intra(torch.from_numpy(input_g2g))\n",
    "# initialize a gene expression matrix\n",
    "model_rev.set_gex(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c5792-d5d1-4189-8db5-bd93d4f01508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# setup the initial optimizer\n",
    "optimizer = torch.optim.SGD(model_rev.parameters(), lr=learning_rate, momentum=0)\n",
    "# keep track of the losses per data object\n",
    "loss, losses = None, []\n",
    "# train the model\n",
    "model_rev.train()\n",
    "# work through epochs\n",
    "for epoch in tqdm(range(epochs), total=epochs):\n",
    "    # loop thorugh each data object\n",
    "    losses_ = []\n",
    "    for data in data_loader:\n",
    "        # set the appropriate gex\n",
    "        model_rev.set_gex(data.x)\n",
    "        # derive the message as well as the mean field approximation\n",
    "        msg, msg_intra, log_z_mft = model_rev(data.edge_index, 1)\n",
    "        # compute the loss and track it\n",
    "        loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model_rev.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model_rev.gex))) )\n",
    "        losses_.append(loss.detach().numpy()[0][0])\n",
    "        # derive the gradients, update, and clear\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # repeatedly force a normalization\n",
    "        model_rev.conv1.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev.conv1.lin.weight), requires_grad=True)\n",
    "        model_rev.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev.lin.weight), requires_grad=True)\n",
    "        optimizer = torch.optim.SGD(model_rev.parameters(), lr=learning_rate, momentum=0)\n",
    "    # now take the average loss of the objects\n",
    "    losses.append(np.mean(losses_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37420ee-99b3-477a-b396-31e698cd80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot\n",
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax.grid(False)\n",
    "ax.plot(losses, lw=2, color='#fe86a4')\n",
    "ax.set_xlim(0, epochs)\n",
    "vmin, vmax = min(min(losses), 0), max(losses)\n",
    "vstep = (vmax - vmin) * 0.01\n",
    "ax.set_ylim(vmin-vstep, vmax+vstep)\n",
    "ax.set(xlabel='epochs', ylabel='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3ac19-8c84-431d-bd69-ce79ae81b7e7",
   "metadata": {},
   "source": [
    "## perturb the lesions based on learned links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7044d67-ef40-49f9-a81e-32dc172d1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to derive the gex from the sphex\n",
    "def calc_gex(sphex):\n",
    "    \"\"\"\n",
    "    Calculates the gene expression matrix from the spherical\n",
    "    \"\"\"\n",
    "    # setup the gex\n",
    "    n_genes = sphex.shape[1]+1\n",
    "    gex = torch.from_numpy(np.zeros((sphex.shape[0], n_genes)).astype('float32'))\n",
    "    # compute the gex\n",
    "    for idx in range(n_genes):\n",
    "        if idx == n_genes-1:\n",
    "            gex[:,idx] = torch.sin(sphex[:,idx-1])\n",
    "        else:\n",
    "            gex[:,idx] = torch.cos(sphex[:,idx])\n",
    "        for idx_ in range(idx):\n",
    "            gex[:,idx] *= torch.sin(sphex[:,idx_])\n",
    "    return torch.nan_to_num(gex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295b4a0-8505-4a5b-963d-34db037047f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to derive the gex from the sphex\n",
    "def calc_sphex(gex):\n",
    "    \"\"\"\n",
    "    Calculates the spherical expression matrix from the normal\n",
    "    \"\"\"\n",
    "    # setup the gex\n",
    "    n_sgenes = gex.shape[1]-1\n",
    "    sphex = torch.from_numpy(np.zeros((gex.shape[0], n_sgenes)).astype('float32'))\n",
    "    # compute the gex\n",
    "    for idx in tqdm(range(n_sgenes), total=n_sgenes):\n",
    "        sphex[:,idx] = gex[:,idx]\n",
    "        for idx_ in range(idx):\n",
    "            sphex[:,idx] /= torch.sin(sphex[:,idx_])\n",
    "        sphex[:,idx] = torch.arccos(sphex[:,idx])\n",
    "    return sphex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1252b-c782-4862-a7f3-010e0f148137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the celcomen class\n",
    "class simcomen(torch.nn.Module):\n",
    "    # define initialization function\n",
    "    def __init__(self, input_dim, output_dim, n_neighbors, seed=0):\n",
    "        super(simcomen, self).__init__()\n",
    "        # define the seed\n",
    "        torch.manual_seed(seed)\n",
    "        # set up the graph convolution\n",
    "        self.conv1 = GCNConv(input_dim, output_dim, add_self_loops=False)\n",
    "        # set up the linear layer for intracellular gene regulation\n",
    "        self.lin = torch.nn.Linear(input_dim, output_dim)\n",
    "        # define the neighbors\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # define a tracking variable for the gene expression x matrix\n",
    "        self.sphex = None\n",
    "        self.gex = None\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g(self, g2g):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g matrix to be a specified interaction matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.conv1.lin.weight = torch.nn.Parameter(g2g, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(n_genes).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g_intra(self, g2g_intra):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g intracellular matrix to be a specified matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.lin.weight = torch.nn.Parameter(g2g_intra, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.lin.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g_intra)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the sphex matrix\n",
    "    def set_sphex(self, sphex):\n",
    "        \"\"\"\n",
    "        Artifically sets the current sphex matrix\n",
    "        \"\"\"\n",
    "        self.sphex = torch.nn.Parameter(sphex, requires_grad=True)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction or training,\n",
    "        convolutes the input by the expected interactions and returns log(Z_mft)\n",
    "        \"\"\"\n",
    "        # compute the gex\n",
    "        self.gex = calc_gex(self.sphex)\n",
    "        # compute the message\n",
    "        msg = self.conv1(self.gex, edge_index)\n",
    "        # compute intracellular message\n",
    "        msg_intra = self.lin(self.gex)\n",
    "        # compute the log z mft\n",
    "        log_z_mft = self.log_Z_mft(edge_index, batch)\n",
    "        return msg, msg_intra, log_z_mft\n",
    "\n",
    "    # define approximation function\n",
    "    def log_Z_mft(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Mean Field Theory approximation to the partition function. Assumptions used are:\n",
    "        - expression of values of genes are close to their mean values over the visium slide\n",
    "        - \\sum_b g_{a,b} m^b >0 \\forall a, where m is the mean gene expression and g is the gene-gene\n",
    "          interaction matrix.\n",
    "        \"\"\"\n",
    "        # retrieve number of spots\n",
    "        num_spots = self.gex.shape[0]\n",
    "        # calculate mean gene expression        \n",
    "        mean_genes = torch.mean(self.gex, axis=0).reshape(-1,1)  # the mean should be per connected graph\n",
    "        # calculate the norm of the sum of mean genes\n",
    "        g = torch.norm(torch.mm( self.n_neighbors*self.conv1.lin.weight + 2*self.lin.weight, mean_genes))   # maybe needs to change to g = torch.norm(torch.mm(mean_genes, self.conv1.lin.weight))\n",
    "        # calculate the contribution for mean values        \n",
    "        z_mean = - num_spots  * torch.mm(torch.mm(torch.t(mean_genes), self.lin.weight + 0.5 * self.n_neighbors * self.conv1.lin.weight),  mean_genes)\n",
    "        # calculate the contribution gene interactions\n",
    "        z_interaction = self.z_interaction(num_spots=num_spots, g=g)\n",
    "        # add the two contributions        \n",
    "        log_z_mft = z_mean + z_interaction\n",
    "        return log_z_mft\n",
    "\n",
    "    def z_interaction(self, num_spots, g):\n",
    "        \"\"\"\n",
    "        Avoid exploding exponentials by returning an approximate interaction term for the partition function.\n",
    "        \"\"\"\n",
    "        if g>20:\n",
    "            z_interaction = num_spots * ( g - torch.log( g) )\n",
    "        else:\n",
    "            z_interaction = num_spots * torch.log((torch.exp( g) - torch.exp(- g))/( g))\n",
    "        return z_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e06eb9-c1dd-43d5-bfff-42159d2c1744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report the current Tgfbr2 and Jak2 expression for each of our lung pieces\n",
    "for name, a_obj in a_objs.items():\n",
    "    values = sc.get.obs_df(a_obj, keys=['Tgfbr2']).mean(0)\n",
    "    values.name = name\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f94675-f277-44f5-be62-564701fa97dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a copy of the objects to perform Tgfbr2 KO experiments\n",
    "avis_subs = {k:v[:, genes].copy() for k,v in a_objs.items()}\n",
    "for name, avis_sub in avis_subs.items():\n",
    "    # retrieve the current values\n",
    "    proposed_x = avis_sub.X.toarray().copy()\n",
    "    sc.pl.spatial(avis_sub, color=['Tgfbr2'], use_raw=False, s=10)\n",
    "    # adjust the X so we artificially introduce signaling to a random part of the tissue\n",
    "    np.random.seed(0)\n",
    "    df_gex = sc.get.obs_df(avis_sub, keys=['Tgfbr2'])['Tgfbr2']\n",
    "    mask = avis_sub.obs.index == np.random.choice(avis_sub.obs.index[df_gex > 0], size=1)[0]\n",
    "    idx = np.where(avis_sub.var_names == 'Tgfbr2')[0][0]\n",
    "    proposed_x[mask, idx] = 0\n",
    "    avis_sub.obs['perturbed'] = 'unperturbed'\n",
    "    avis_sub.obs.loc[mask, 'perturbed'] = 'perturbed'\n",
    "    avis_sub.uns['perturbed_colors'] = ['#ff47a6','#f7ebf1']\n",
    "    sc.pl.spatial(avis_sub, color=['perturbed'], use_raw=False, s=10)\n",
    "    avis_sub.X = proposed_x\n",
    "    avis_subs[name] = avis_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d93bd-6c5f-408f-903a-af074afae8c9",
   "metadata": {},
   "source": [
    "## work through one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68472d25-98db-44ed-8ff5-8e8abf3f2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide an example\n",
    "sc.pl.spatial(avis_sub, color=['Tgfbr2'], use_raw=False, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f777e-3ce0-4e99-8980-2fcf9098e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameters of the model\n",
    "n_genes = avis_sub.shape[1]\n",
    "learning_rate = 1e-3\n",
    "zmft_scalar = 1e-1\n",
    "seed = 0\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db436e7-e044-46e6-87d0-4e5195e0cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve positions from the data\n",
    "pos = torch.from_numpy(avis_sub.obsm['spatial'])\n",
    "edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "edge_index = torch.from_numpy(np.array(np.where(edge_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab78e1-4c0d-41d7-9056-213ed5fda1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model, input and output will be the same\n",
    "model = simcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "# now perform the simulation\n",
    "np.random.seed(seed)\n",
    "# convert the gene expression data to numpy\n",
    "x = torch.from_numpy(avis_sub.X)\n",
    "# sphere normalize the data (just in case)\n",
    "norm_factor = torch.sqrt(torch.pow(x, 2).sum(1)).reshape(-1,1)\n",
    "assert (norm_factor > 0).all()\n",
    "x = torch.div(x, norm_factor)\n",
    "# artifically set the g2g matrix\n",
    "model.set_g2g(model_rev.conv1.lin.weight.clone().detach())\n",
    "model.set_g2g_intra(model_rev.lin.weight.clone().detach())\n",
    "# initialize a gene expression matrix\n",
    "input_sphex = calc_sphex(x).clone().detach().numpy()\n",
    "model.set_sphex(torch.from_numpy(input_sphex.astype('float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f52428-1427-4bf4-8265-7a6ca8eee31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "# keep track of the losses per data object\n",
    "loss, losses = None, []\n",
    "# train the model\n",
    "model.train()\n",
    "tmp_gexs = []\n",
    "# work through epochs\n",
    "for epoch in tqdm(range(epochs), total=epochs):\n",
    "    # derive the message as well as the mean field approximation\n",
    "    msg, msg_intra, log_z_mft = model(edge_index, 1)\n",
    "    if (epoch % 5) == 0:\n",
    "        tmp_gex = model.gex.clone().detach().numpy()\n",
    "        tmp_gexs.append(tmp_gex)\n",
    "    # compute the loss and track it\n",
    "    loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model.gex))) )\n",
    "    losses.append(loss.detach().numpy()[0][0])\n",
    "    # derive the gradients, update, and clear\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e2ba3-198f-4c52-9491-1d3ab54eee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss\n",
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax.grid(False)\n",
    "ax.plot(losses, lw=2, color='#fe86a4')\n",
    "ax.set_xlim(0, epochs)\n",
    "vmin, vmax = min(min(losses), 0), max(losses)\n",
    "vstep = (vmax - vmin) * 0.01\n",
    "ax.set_ylim(vmin-vstep, vmax+vstep)\n",
    "ax.set(xlabel='epochs', ylabel='loss')\n",
    "# retrieve the data\n",
    "output_gex = model.gex.detach().numpy()\n",
    "output_msg = msg.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72827aa-8635-42b9-a11c-04e8ce83ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the layers\n",
    "for idx, tmp_gex in enumerate(tmp_gexs):\n",
    "    avis_sub.layers[f'input{idx}'] = tmp_gex\n",
    "avis_sub.layers['output'] = output_gex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc9cc0-f52f-4996-be84-a18f1a7f8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the differential within the area of interest vs outside\n",
    "avis_sub.layers['diff'] = avis_sub.layers['output'] - avis_sub.layers['input0']\n",
    "mask0 = avis_sub.obs['perturbed'] == 'unperturbed'\n",
    "mask1 = avis_sub.obs['perturbed'] == 'perturbed'\n",
    "diff_in_vs_out_p = pd.Series(avis_sub.layers['diff'][mask1].mean(0) - avis_sub.layers['diff'][mask0].mean(0),\n",
    "                             index=avis_sub.var_names).sort_values()[::-1]\n",
    "# remove the perturbed genes to get a clean look\n",
    "perturbed_genes = ['Tgfbr2']\n",
    "perturbed_label = 'Tgfbr2'\n",
    "diff_in_vs_out_p = diff_in_vs_out_p.loc[~diff_in_vs_out_p.index.isin(perturbed_genes)]\n",
    "diff_in_vs_out_p -= diff_in_vs_out_p.min()\n",
    "diff_in_vs_out_p /= diff_in_vs_out_p.max()\n",
    "\n",
    "# perform the differential with sphere normed data\n",
    "# > WT\n",
    "x = torch.from_numpy(avis_sub.copy().X)\n",
    "norm_factor = torch.sqrt(torch.pow(x, 2).sum(1)).reshape(-1,1)\n",
    "assert (norm_factor > 0).all()\n",
    "x1 = torch.div(x, norm_factor)\n",
    "# > TGFBR2 KO\n",
    "x = torch.from_numpy(a[a.obs['phenotypes'].astype(str).str.startswith('Tgfbr2'), avis_sub.var.index].X.toarray())\n",
    "norm_factor = torch.sqrt(torch.pow(x, 2).sum(1)).reshape(-1,1)\n",
    "assert (norm_factor > 0).all()\n",
    "x2 = torch.div(x, norm_factor)\n",
    "diff_tgfbr2ko_vs_wt = pd.Series(x2.mean(0) - x1.mean(0), index=avis_sub.var.index)\n",
    "diff_tgfbr2ko_vs_wt = diff_tgfbr2ko_vs_wt.loc[~diff_tgfbr2ko_vs_wt.index.isin(perturbed_genes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa935c0-e522-465e-891a-28b018b2a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation\n",
    "idxs = diff_in_vs_out_p.index.intersection(diff_tgfbr2ko_vs_wt.index)\n",
    "print('Perturbed', ss.spearmanr(diff_in_vs_out_p.loc[idxs], diff_tgfbr2ko_vs_wt.loc[idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b0e15c-6493-4c5d-8d1c-f21b21abd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the dataframe on percentile basis\n",
    "idxs = diff_in_vs_out_p.index.intersection(diff_tgfbr2ko_vs_wt.index)\n",
    "df = pd.concat([diff_in_vs_out_p.loc[idxs], diff_tgfbr2ko_vs_wt.loc[idxs]], axis=1)\n",
    "df.columns = ['Obs','Exp']\n",
    "df['Bin'] = np.nan\n",
    "# derive the bins\n",
    "vmin = min(diff_tgfbr2ko_vs_wt.loc[idxs])\n",
    "step_size = 20\n",
    "for step in range(100//step_size):\n",
    "    vmax = np.percentile(df['Exp'], (step+1)*step_size)\n",
    "    mask = (df['Exp'] >= vmin) & (df['Exp'] < vmax)\n",
    "    vmin = vmax\n",
    "    genes = df['Exp'].index[mask]\n",
    "    df.loc[genes, 'Bin'] = str(int((step+1)*step_size))\n",
    "# plot the bars\n",
    "fig, ax = plt.subplots(figsize=[3, 4])\n",
    "ax.grid(False)\n",
    "sns.boxplot(x='Bin', y='Obs', data=df, saturation=1, linewidth=2,\n",
    "            order=['20','40','60','80','100'], palette=['#ff47a6','#f593c2','#f7cbe0','#f7ebf1','#ffffff'][::-1])\n",
    "ax.set_xlim(-1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c7264-f3f2-4f54-9a17-a821be5bd917",
   "metadata": {},
   "source": [
    "## replicate with all areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6d752-6af0-4fd1-9019-8f2e3a20f9b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create tracking variables\n",
    "rho, pval = ss.spearmanr(diff_in_vs_out_p.loc[idxs], diff_tgfbr2ko_vs_wt.loc[idxs])\n",
    "rhos, pvals = {'a5':rho}, {'a5':pval}\n",
    "# perform the model perturbation for all areas\n",
    "for name, avis_sub in avis_subs.items():\n",
    "    if name == 'a5': continue\n",
    "    print('Processing', name)\n",
    "    ### TRAIN\n",
    "    # retrieve positions from the data\n",
    "    pos = torch.from_numpy(avis_sub.obsm['spatial'])\n",
    "    edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "    edge_index = torch.from_numpy(np.array(np.where(edge_index)))\n",
    "\n",
    "    # instantiate the model, input and output will be the same\n",
    "    model = simcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "    # now perform the simulation\n",
    "    np.random.seed(seed)\n",
    "    # convert the gene expression data to numpy\n",
    "    x = torch.from_numpy(avis_sub.X)\n",
    "    # sphere normalize the data (just in case)\n",
    "    norm_factor = torch.sqrt(torch.pow(x, 2).sum(1)).reshape(-1,1)\n",
    "    assert (norm_factor > 0).all()\n",
    "    x = torch.div(x, norm_factor)\n",
    "    # artifically set the g2g matrix\n",
    "    model.set_g2g(model_rev.conv1.lin.weight.clone().detach())\n",
    "    model.set_g2g_intra(model_rev.lin.weight.clone().detach())\n",
    "    # initialize a gene expression matrix\n",
    "    input_sphex = calc_sphex(x).clone().detach().numpy()\n",
    "    model.set_sphex(torch.from_numpy(input_sphex.astype('float32')))\n",
    "    \n",
    "    # set up the optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "    # keep track of the losses per data object\n",
    "    loss, losses = None, []\n",
    "    # train the model\n",
    "    model.train()\n",
    "    tmp_gexs = []\n",
    "    # work through epochs\n",
    "    for epoch in tqdm(range(epochs), total=epochs):\n",
    "        # derive the message as well as the mean field approximation\n",
    "        msg, msg_intra, log_z_mft = model(edge_index, 1)\n",
    "        if (epoch % 5) == 0:\n",
    "            tmp_gex = model.gex.clone().detach().numpy()\n",
    "            tmp_gexs.append(tmp_gex)\n",
    "        # compute the loss and track it\n",
    "        loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model.gex))) )\n",
    "        losses.append(loss.detach().numpy()[0][0])\n",
    "        # derive the gradients, update, and clear\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    ### LOSS\n",
    "    # plot the loss\n",
    "    fig, ax = plt.subplots(figsize=[6, 4])\n",
    "    ax.grid(False)\n",
    "    ax.plot(losses, lw=2, color='#fe86a4')\n",
    "    ax.set_xlim(0, epochs)\n",
    "    vmin, vmax = min(min(losses), 0), max(losses)\n",
    "    vstep = (vmax - vmin) * 0.01\n",
    "    ax.set_ylim(vmin-vstep, vmax+vstep)\n",
    "    ax.set(xlabel='epochs', ylabel='loss')\n",
    "    # retrieve the data\n",
    "    output_gex = model.gex.detach().numpy()\n",
    "    \n",
    "    ### DIFFERENTIAL\n",
    "    # add the layers\n",
    "    for idx, tmp_gex in enumerate(tmp_gexs):\n",
    "        avis_sub.layers[f'input{idx}'] = tmp_gex\n",
    "    avis_sub.layers['output'] = output_gex\n",
    "    \n",
    "    # compute the differential within the area of interest vs outside\n",
    "    avis_sub.layers['diff'] = avis_sub.layers['output'] - avis_sub.layers['input0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc290c2-3f98-4232-9f17-581562c07d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot as box plot\n",
    "rand_rhos, rand_pvals = {}, {}\n",
    "for name, avis_sub in avis_subs.items():\n",
    "    np.random.seed(0)\n",
    "    ### DIFFERENTIAL\n",
    "    mask0 = avis_sub.obs['perturbed'] == 'unperturbed'\n",
    "    mask1 = avis_sub.obs['perturbed'] == 'perturbed'\n",
    "    diff_in_vs_out_p = pd.Series(avis_sub.layers['diff'][mask1].mean(0) - avis_sub.layers['diff'][mask0].mean(0),\n",
    "                                 index=avis_sub.var_names).sort_values()[::-1]\n",
    "    diff_in_vs_out_p -= diff_in_vs_out_p.min()\n",
    "    diff_in_vs_out_p /= diff_in_vs_out_p.max()\n",
    "    # remove the perturbed genes to get a clean look\n",
    "    perturbed_genes = ['Tgfbr2']\n",
    "    perturbed_label = 'Tgfbr2'\n",
    "    diff_in_vs_out_p = diff_in_vs_out_p.loc[~diff_in_vs_out_p.index.isin(perturbed_genes)]\n",
    "\n",
    "    ### CORRELATION\n",
    "    # compute the correlation\n",
    "    idxs = diff_in_vs_out_p.index.intersection(diff_tgfbr2ko_vs_wt.index)\n",
    "    rho, pval = ss.spearmanr(diff_in_vs_out_p.loc[idxs], diff_tgfbr2ko_vs_wt.loc[idxs])\n",
    "    rhos[name] = rho; pvals[name] = pval\n",
    "    print(name)\n",
    "    print('Perturbed', rho, pval)\n",
    "    # perform random shuffling\n",
    "    rho, pval = ss.spearmanr(np.random.choice(diff_in_vs_out_p.loc[idxs], size=len(idxs), replace=False),\n",
    "                             np.random.choice(diff_tgfbr2ko_vs_wt.loc[idxs], size=len(idxs), replace=False))\n",
    "    rand_rhos[name] = rho; rand_pvals[name] = pval\n",
    "    print('Random', rho, pval)\n",
    "    \n",
    "    ### PLOTTING\n",
    "    # setup the dataframe\n",
    "    idxs = diff_in_vs_out_p.index.intersection(diff_tgfbr2ko_vs_wt.index)\n",
    "    df = pd.concat([diff_in_vs_out_p.loc[idxs], diff_tgfbr2ko_vs_wt.loc[idxs]], axis=1)\n",
    "    df.columns = ['Obs','Exp']\n",
    "    df['Bin'] = np.nan\n",
    "    # derive the bins\n",
    "    vmin = min(diff_tgfbr2ko_vs_wt.loc[idxs])\n",
    "    step_size = 20\n",
    "    for step in range(100//step_size):\n",
    "        vmax = np.percentile(df['Exp'], (step+1)*step_size)\n",
    "        mask = (df['Exp'] >= vmin) & (df['Exp'] < vmax)\n",
    "        vmin = vmax\n",
    "        genes = df['Exp'].index[mask]\n",
    "        df.loc[genes, 'Bin'] = str(int((step+1)*step_size))\n",
    "    # plot the bars\n",
    "    fig, ax = plt.subplots(figsize=[3, 4])\n",
    "    ax.grid(False)\n",
    "    sns.boxplot(x='Bin', y='Obs', data=df, saturation=1, linewidth=2,\n",
    "                order=['20','40','60','80','100'], palette=['#ff47a6','#f593c2','#f7cbe0','#f7ebf1','#ffffff'][::-1])\n",
    "    ax.set_xlim(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93780b9b-b401-492a-b59b-6ce76acbff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine them all together\n",
    "fig, ax = plt.subplots(figsize=[4, 4])\n",
    "ax.grid(False)\n",
    "ax.scatter(list(rand_rhos.values()), -np.log10(list(rand_pvals.values())), edgecolor='k', color='white')\n",
    "ax.scatter(list(rhos.values()), -np.log10(list(pvals.values())), edgecolor='k', color='#ff47a6')\n",
    "# report the statistics\n",
    "print(ss.mannwhitneyu(list(rhos.values()), list(rand_rhos.values())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (base_py39)",
   "language": "python",
   "name": "base_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
