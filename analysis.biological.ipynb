{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14883ee2-1de0-4d82-b6e7-a8537c14d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# set figure parameters\n",
    "sc.settings.set_figure_params(dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c9f2a9-ce5f-4b39-aa2c-fbaea099eacc",
   "metadata": {},
   "source": [
    "## define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9a423-4207-46c9-9737-8b24dba2392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to gather positions\n",
    "def get_pos(n_x, n_y):\n",
    "    # create the hex lattice\n",
    "    xs = np.array([np.arange(0, n_x) + 0.5 if idx % 2 == 0 else np.arange(0, n_x) for idx in range(n_y)])\n",
    "    # derive the y-step given a distance of one\n",
    "    y_step = np.sqrt(1**2+0.5**2)\n",
    "    ys = np.array([[y_step * idy] * n_x for idy in range(n_y)])\n",
    "    # define the positions\n",
    "    pos = np.vstack([xs.flatten(), ys.flatten()]).T\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb73a07-99a3-4e5e-8903-13d93085d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to derive the gex from the sphex\n",
    "def calc_gex(sphex):\n",
    "    \"\"\"\n",
    "    Calculates the gene expression matrix from the spherical\n",
    "    \"\"\"\n",
    "    # setup the gex\n",
    "    n_genes = sphex.shape[1]+1\n",
    "    gex = torch.from_numpy(np.zeros((sphex.shape[0], n_genes)).astype('float32'))\n",
    "    # compute the gex\n",
    "    for idx in range(n_genes):\n",
    "        if idx == n_genes-1:\n",
    "            gex[:,idx] = torch.sin(sphex[:,idx-1])\n",
    "        else:\n",
    "            gex[:,idx] = torch.cos(sphex[:,idx])\n",
    "        for idx_ in range(idx):\n",
    "            gex[:,idx] *= torch.sin(sphex[:,idx_])\n",
    "    return gex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105fd41-cbf9-4574-ad38-94a006f94bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "# define the number of neighbors (six for visium)\n",
    "n_neighbors = 6\n",
    "# define the simcomen class\n",
    "class simcomen(torch.nn.Module):\n",
    "    # define initialization function\n",
    "    def __init__(self, input_dim, output_dim, n_neighbors, seed=0):\n",
    "        super(simcomen, self).__init__()\n",
    "        # define the seed\n",
    "        torch.manual_seed(seed)\n",
    "        # set up the graph convolution\n",
    "        self.conv1 = GCNConv(input_dim, output_dim, add_self_loops=False)\n",
    "        # set up the linear layer for intracellular gene regulation\n",
    "        self.lin = torch.nn.Linear(input_dim, output_dim)\n",
    "        # define the neighbors\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # define a tracking variable for the gene expression x matrix\n",
    "        self.sphex = None\n",
    "        self.gex = None\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g(self, g2g):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g matrix to be a specified interaction matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.conv1.lin.weight = torch.nn.Parameter(g2g, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(n_genes).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g_intra(self, g2g_intra):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g intracellular matrix to be a specified matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.lin.weight = torch.nn.Parameter(g2g_intra, requires_grad=False)\n",
    "        # and then set the bias as all zeros\n",
    "        self.lin.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g_intra)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the sphex matrix\n",
    "    def set_sphex(self, sphex):\n",
    "        \"\"\"\n",
    "        Artifically sets the current sphex matrix\n",
    "        \"\"\"\n",
    "        self.sphex = torch.nn.Parameter(sphex, requires_grad=True)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction or training,\n",
    "        convolutes the input by the expected interactions and returns log(Z_mft)\n",
    "        \"\"\"\n",
    "        # compute the gex\n",
    "        self.gex = calc_gex(self.sphex)\n",
    "        # compute the message\n",
    "        msg = self.conv1(self.gex, edge_index)\n",
    "        # compute intracellular message\n",
    "        msg_intra = self.lin(self.gex)\n",
    "        # compute the log z mft\n",
    "        log_z_mft = self.log_Z_mft(edge_index, batch)\n",
    "        return msg, msg_intra, log_z_mft\n",
    "\n",
    "    # define approximation function\n",
    "    def log_Z_mft(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Mean Field Theory approximation to the partition function. Assumptions used are:\n",
    "        - expression of values of genes are close to their mean values over the visium slide\n",
    "        - \\sum_b g_{a,b} m^b >0 \\forall a, where m is the mean gene expression and g is the gene-gene\n",
    "          interaction matrix.\n",
    "        \"\"\"\n",
    "        # retrieve number of spots\n",
    "        num_spots = self.gex.shape[0]\n",
    "        # calculate mean gene expression        \n",
    "        mean_genes = torch.mean(self.gex, axis=0).reshape(-1,1)  # the mean should be per connected graph\n",
    "        # calculate the norm of the sum of mean genes\n",
    "        g = torch.norm(torch.mm( self.n_neighbors*self.conv1.lin.weight + 2*self.lin.weight, mean_genes))   # maybe needs to change to g = torch.norm(torch.mm(mean_genes, self.conv1.lin.weight))\n",
    "        # calculate the contribution for mean values        \n",
    "        z_mean = - num_spots  * torch.mm(torch.mm(torch.t(mean_genes), self.lin.weight + 0.5 * self.n_neighbors * self.conv1.lin.weight),  mean_genes)\n",
    "        # calculate the contribution gene interactions\n",
    "        z_interaction = self.z_interaction(num_spots=num_spots, g=g)\n",
    "        # add the two contributions        \n",
    "        log_z_mft = z_mean + z_interaction\n",
    "        return log_z_mft\n",
    "\n",
    "    def z_interaction(self, num_spots, g):\n",
    "        \"\"\"\n",
    "        Avoid exploding exponentials by returning an approximate interaction term for the partition function.\n",
    "        \"\"\"\n",
    "        if g>20:\n",
    "            z_interaction = num_spots * ( g - torch.log( g) )\n",
    "        else:\n",
    "            z_interaction = num_spots * torch.log((torch.exp( g) - torch.exp(- g))/( g))\n",
    "        return z_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d591b71-cf8e-462a-93fe-7fadcea57a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the celcomen class\n",
    "class celcomen(torch.nn.Module):\n",
    "    # define initialization function\n",
    "    def __init__(self, input_dim, output_dim, n_neighbors, seed=0):\n",
    "        super(celcomen, self).__init__()\n",
    "        # define the seed\n",
    "        torch.manual_seed(seed)\n",
    "        # set up the graph convolution\n",
    "        self.conv1 = GCNConv(input_dim, output_dim, add_self_loops=False)\n",
    "        # set up the linear layer for intracellular gene regulation\n",
    "        self.lin = torch.nn.Linear(input_dim, output_dim)\n",
    "        # define the neighbors\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # define a tracking variable for the gene expression x matrix\n",
    "        self.gex = None\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g(self, g2g):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g matrix to be a specified interaction matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.conv1.lin.weight = torch.nn.Parameter(g2g, requires_grad=True)\n",
    "        # and then set the bias as all zeros\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the g2g matrix\n",
    "    def set_g2g_intra(self, g2g_intra):\n",
    "        \"\"\"\n",
    "        Artifically sets the core g2g intracellular matrix to be a specified matrix\n",
    "        \"\"\"\n",
    "        # set the weight as the input\n",
    "        self.lin.weight = torch.nn.Parameter(g2g_intra, requires_grad=True)\n",
    "        # and then set the bias as all zeros\n",
    "        self.lin.bias = torch.nn.Parameter(torch.from_numpy(np.zeros(len(g2g_intra)).astype('float32')), requires_grad=False)\n",
    "\n",
    "    # define a function to artificially set the sphex matrix\n",
    "    def set_gex(self, gex):\n",
    "        \"\"\"\n",
    "        Artifically sets the current sphex matrix\n",
    "        \"\"\"\n",
    "        self.gex = torch.nn.Parameter(gex, requires_grad=False)\n",
    "        \n",
    "    # define the forward pass\n",
    "    def forward(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Forward pass for prediction or training,\n",
    "        convolutes the input by the expected interactions and returns log(Z_mft)\n",
    "        \"\"\"\n",
    "        # compute the message\n",
    "        msg = self.conv1(self.gex, edge_index)\n",
    "        # compute intracellular message\n",
    "        msg_intra = self.lin(self.gex)\n",
    "        # compute the log z mft\n",
    "        log_z_mft = self.log_Z_mft(edge_index, batch)\n",
    "        return msg, msg_intra, log_z_mft\n",
    "\n",
    "    # define approximation function\n",
    "    def log_Z_mft(self, edge_index, batch):\n",
    "        \"\"\"\n",
    "        Mean Field Theory approximation to the partition function. Assumptions used are:\n",
    "        - expression of values of genes are close to their mean values over the visium slide\n",
    "        - \\sum_b g_{a,b} m^b >0 \\forall a, where m is the mean gene expression and g is the gene-gene\n",
    "          interaction matrix.\n",
    "        \"\"\"\n",
    "        # retrieve number of spots\n",
    "        num_spots = self.gex.shape[0]\n",
    "        # calculate mean gene expression        \n",
    "        mean_genes = torch.mean(self.gex, axis=0).reshape(-1,1)  # the mean should be per connected graph\n",
    "        # calculate the norm of the sum of mean genes\n",
    "        g = torch.norm(torch.mm( self.n_neighbors*self.conv1.lin.weight + 2*self.lin.weight, mean_genes))   # maybe needs to change to g = torch.norm(torch.mm(mean_genes, self.conv1.lin.weight))\n",
    "        # calculate the contribution for mean values        \n",
    "        z_mean = - num_spots  * torch.mm(torch.mm(torch.t(mean_genes), self.lin.weight + 0.5 * self.n_neighbors * self.conv1.lin.weight),  mean_genes)\n",
    "        # calculate the contribution gene interactions\n",
    "        z_interaction = self.z_interaction(num_spots=num_spots, g=g)\n",
    "        # add the two contributions        \n",
    "        log_z_mft = z_mean + z_interaction\n",
    "        return log_z_mft\n",
    "\n",
    "    def z_interaction(self, num_spots, g):\n",
    "        \"\"\"\n",
    "        Avoid exploding exponentials by returning an approximate interaction term for the partition function.\n",
    "        \"\"\"\n",
    "        if g>20:\n",
    "            z_interaction = num_spots * ( g - torch.log( g) )\n",
    "        else:\n",
    "            z_interaction = num_spots * torch.log((torch.exp( g) - torch.exp(- g))/( g))\n",
    "        return z_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32918cf7-8584-4b61-ada9-05dc71725751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to normalize the g2g\n",
    "def normalize_g2g(g2g):\n",
    "    \"\"\"\n",
    "    Addresses any small fluctuations in symmetrical weights\n",
    "    \"\"\"\n",
    "    # symmetrize the values\n",
    "    g2g = (g2g + g2g.T) / 2\n",
    "    # force them to be between 0-1\n",
    "    g2g[g2g < 0] = 0\n",
    "    g2g[g2g > 1] = 1\n",
    "    # force the central line to be 1\n",
    "    for idx in range(len(g2g)):\n",
    "        g2g[idx, idx] = 1\n",
    "    return g2g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b698ba-f779-403c-809c-2861a5ecdcab",
   "metadata": {},
   "source": [
    "## learn fetal spleen immune data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ff178-5048-4ed2-9520-3ec4b1e5e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "avis = sc.read_h5ad('Visium10X_data_SP.h5ad')\n",
    "avis.var_names = avis.var_names.astype(str)\n",
    "avis.var_names_make_unique()\n",
    "# compute PCA for the spatial dataset using HVGs\n",
    "avis.uns['log1p']['base'] = np.e\n",
    "sc.pp.highly_variable_genes(avis, flavor='seurat', min_mean=0.5, max_mean=7.5, min_disp=0.5, n_top_genes=300)\n",
    "sc.pl.highly_variable_genes(avis)\n",
    "# define the sample indexing\n",
    "sample_col = 'sample_id'\n",
    "samples = avis.obs[sample_col].unique()\n",
    "# report how many HVGs we're going to use\n",
    "print('there are', avis.var['highly_variable'].sum(), 'hvgs')\n",
    "# create a gene subset for testing\n",
    "genes = avis.var_names[avis.var['highly_variable']].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1b4d8-699c-4c47-b240-ec2975bb5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tracking variable of the datas for the dataloader\n",
    "data_list = []\n",
    "# loop through each sample\n",
    "for sample in samples:\n",
    "    # define the mask\n",
    "    mask = avis.obs[sample_col] == sample\n",
    "    # retrieve positions from the data\n",
    "    pos = torch.from_numpy(avis[mask].obsm['spatial'])\n",
    "    # convert the gene expression data to numpy\n",
    "    x = torch.from_numpy(avis[mask, genes].X.todense())\n",
    "    # sphere normalize the data (just in case)\n",
    "    norm_factor = torch.pow(x, 2).sum(1).reshape(-1,1)\n",
    "    assert (norm_factor > 0).all()\n",
    "    x = torch.div(x, norm_factor)\n",
    "    y = torch.Tensor([0])  # here we will store GT value\n",
    "    # find the edges via kneighbors, not including self because we are considering intercellular\n",
    "    edge_index = kneighbors_graph(pos, n_neighbors, include_self=False).todense()\n",
    "    edge_index = torch.from_numpy(np.array(np.where(edge_index)))\n",
    "    # create the final torch geometric graph dataframe\n",
    "    data = torch_geometric.data.Data(x=x, pos=pos, y=y, edge_index=edge_index)\n",
    "    data.validate(raise_on_error=True)  # performs basic checks on the graph\n",
    "    # store the data in the data list tracker\n",
    "    data_list.append(data)\n",
    "# convert into a data loader\n",
    "data_loader = DataLoader(data_list, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36eed31-559d-489d-a1d0-f7642f00ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# define the parameters of the model\n",
    "n_genes = len(genes)\n",
    "learning_rate = 5e-2\n",
    "learning_rate_all = 5e-2\n",
    "zmft_scalar = 1e-1\n",
    "seed = 0\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190ed07-714b-4e09-8a50-016400dbb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the held out sample\n",
    "final_rs = pd.DataFrame(columns=['seed','r','p','pr','pp'])\n",
    "final_rs_intra = pd.DataFrame(columns=['seed','r','p','pr','pp'])\n",
    "for held_out in range(len(samples)):\n",
    "    # instantiate the model, input and output will be the same\n",
    "    model_rev_all = celcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "    model_rev = celcomen(input_dim=n_genes, output_dim=n_genes, n_neighbors=n_neighbors, seed=seed)\n",
    "    # now perform the simulation\n",
    "    np.random.seed(seed)\n",
    "    # artifically set the g2g matrix\n",
    "    input_g2g = np.random.uniform(size=(n_genes, n_genes)).astype('float32')\n",
    "    input_g2g = normalize_g2g((input_g2g + input_g2g.T) / 2)\n",
    "    model_rev_all.set_g2g(torch.from_numpy(input_g2g))\n",
    "    model_rev_all.set_g2g_intra(torch.from_numpy(input_g2g))\n",
    "    input_g2g = np.random.uniform(size=(n_genes, n_genes)).astype('float32')\n",
    "    input_g2g = normalize_g2g((input_g2g + input_g2g.T) / 2)\n",
    "    model_rev.set_g2g(torch.from_numpy(input_g2g))\n",
    "    model_rev.set_g2g_intra(torch.from_numpy(input_g2g))\n",
    "    \n",
    "    # setup the initial optimizer\n",
    "    optimizer_all = torch.optim.SGD(model_rev_all.parameters(), lr=learning_rate_all, momentum=0)\n",
    "    optimizer = torch.optim.SGD(model_rev.parameters(), lr=learning_rate, momentum=0)\n",
    "    # keep track of the losses per data object\n",
    "    loss_all, losses_all = None, []\n",
    "    loss, losses = None, []\n",
    "    df_rs = pd.DataFrame(columns=['epoch','r','p','pr','pp'])\n",
    "    df_rs_intra = pd.DataFrame(columns=['epoch','r','p','pr','pp'])\n",
    "    # train the model\n",
    "    model_rev_all.train()\n",
    "    model_rev.train()\n",
    "    # retrieve the two matrices\n",
    "    epoch = -1\n",
    "    g2g = model_rev.conv1.lin.weight.detach().numpy()\n",
    "    g2g_all = model_rev_all.conv1.lin.weight.detach().numpy()\n",
    "    r, p = ss.spearmanr(g2g.flatten(), g2g_all.flatten())\n",
    "    pr, pp = ss.spearmanr(np.random.choice(g2g.flatten(), size=np.product(g2g.shape)),\n",
    "                          np.random.choice(g2g_all.flatten(), size=np.product(g2g_all.shape)))\n",
    "    df_rs.loc[df_rs.shape[0]] = epoch, r, p, pr, pp\n",
    "    # now for the intra version\n",
    "    g2g = model_rev.lin.weight.detach().numpy()\n",
    "    g2g_all = model_rev_all.lin.weight.detach().numpy()\n",
    "    r, p = ss.spearmanr(g2g.flatten(), g2g_all.flatten())\n",
    "    pr, pp = ss.spearmanr(np.random.choice(g2g.flatten(), size=np.product(g2g.shape)),\n",
    "                          np.random.choice(g2g_all.flatten(), size=np.product(g2g_all.shape)))\n",
    "    df_rs_intra.loc[df_rs_intra.shape[0]] = epoch, r, p, pr, pp\n",
    "    # work through epochs\n",
    "    for epoch in tqdm(range(epochs), total=epochs):\n",
    "        # loop thorugh each data object\n",
    "        losses_ = []\n",
    "        losses_all_ = []\n",
    "        for idx, data in enumerate(data_loader):\n",
    "            # process separately for the special one\n",
    "            if idx == held_out:\n",
    "                # set the appropriate gex\n",
    "                model_rev.set_gex(data.x)\n",
    "                # derive the message as well as the mean field approximation\n",
    "                msg, msg_intra, log_z_mft = model_rev(data.edge_index, 1)\n",
    "                # compute the loss and track it\n",
    "                loss = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model_rev.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model_rev.gex))) )\n",
    "                losses_.append(loss.detach().numpy()[0][0])\n",
    "                # derive the gradients, update, and clear\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # repeatedly force a normalization\n",
    "                model_rev.conv1.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev.conv1.lin.weight), requires_grad=True)\n",
    "                model_rev.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev.lin.weight), requires_grad=True)\n",
    "                optimizer = torch.optim.SGD(model_rev.parameters(), lr=learning_rate, momentum=0)\n",
    "            else:\n",
    "                # set the appropriate gex\n",
    "                model_rev_all.set_gex(data.x)\n",
    "                # derive the message as well as the mean field approximation\n",
    "                msg, msg_intra, log_z_mft = model_rev_all(data.edge_index, 1)\n",
    "                # compute the loss and track it\n",
    "                loss_all = -(-log_z_mft + zmft_scalar * torch.trace(torch.mm(msg, torch.t(model_rev_all.gex))) + zmft_scalar * torch.trace(torch.mm(msg_intra, torch.t(model_rev_all.gex))) )\n",
    "                losses_all_.append(loss_all.detach().numpy()[0][0])\n",
    "                # derive the gradients, update, and clear\n",
    "                loss_all.backward()\n",
    "                optimizer_all.step()\n",
    "                optimizer_all.zero_grad()\n",
    "                # repeatedly force a normalization\n",
    "                model_rev_all.conv1.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev_all.conv1.lin.weight), requires_grad=True)\n",
    "                model_rev_all.lin.weight = torch.nn.Parameter(normalize_g2g(model_rev_all.lin.weight), requires_grad=True)\n",
    "                optimizer_all = torch.optim.SGD(model_rev_all.parameters(), lr=learning_rate_all, momentum=0)\n",
    "        # now take the average loss of the objects\n",
    "        losses.append(np.mean(losses_))\n",
    "        losses_all.append(np.mean(losses_all_))\n",
    "    \n",
    "        # retrieve the two matrices\n",
    "        g2g = model_rev.conv1.lin.weight.detach().numpy()\n",
    "        g2g_all = model_rev_all.conv1.lin.weight.detach().numpy()\n",
    "        r, p = ss.spearmanr(g2g.flatten(), g2g_all.flatten())\n",
    "        pr, pp = ss.spearmanr(np.random.choice(g2g.flatten(), size=np.product(g2g.shape)),\n",
    "                              np.random.choice(g2g_all.flatten(), size=np.product(g2g_all.shape)))\n",
    "        df_rs.loc[df_rs.shape[0]] = epoch, r, p, pr, pp\n",
    "        # now for the intra version\n",
    "        g2g = model_rev.lin.weight.detach().numpy()\n",
    "        g2g_all = model_rev_all.lin.weight.detach().numpy()\n",
    "        r, p = ss.spearmanr(g2g.flatten(), g2g_all.flatten())\n",
    "        pr, pp = ss.spearmanr(np.random.choice(g2g.flatten(), size=np.product(g2g.shape)),\n",
    "                              np.random.choice(g2g_all.flatten(), size=np.product(g2g_all.shape)))\n",
    "        df_rs_intra.loc[df_rs_intra.shape[0]] = epoch, r, p, pr, pp\n",
    "    \n",
    "    # derive the correlation over time\n",
    "    fig, ax = plt.subplots(figsize=[4.1, 4])\n",
    "    ax.grid(False)\n",
    "    ax.plot(df_rs['epoch'], df_rs['r'], color='tab:pink', lw=2)\n",
    "    ax.plot(df_rs['epoch'], df_rs['pr'], color='k', lw=2, linestyle='-')\n",
    "    ax.set_xlim(-2, epochs+1)\n",
    "    ax.set_ylim(-0.01, max(df_rs['r'])*1.01)\n",
    "    ax.set(xlabel='# of epochs passed', ylabel='spearman r')\n",
    "    \n",
    "    # derive the correlation over time\n",
    "    fig, ax = plt.subplots(figsize=[4.1, 4])\n",
    "    ax.grid(False)\n",
    "    ax.plot(df_rs['epoch'], df_rs_intra['r'], color='tab:pink', lw=2)\n",
    "    ax.plot(df_rs['epoch'], df_rs_intra['pr'], color='k', lw=2, linestyle='-')\n",
    "    ax.set_xlim(-2, epochs+1)\n",
    "    ax.set_ylim(-0.01, max(df_rs_intra['r'])*1.01)\n",
    "    ax.set(xlabel='# of epochs passed', ylabel='intra spearman r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd7409-d5f4-44ad-ad05-d9fccd3c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the samples\n",
    "df1 = pd.DataFrame(final_rs['r'].values, columns=['r']); df1['cat'] = 'corr'\n",
    "df2 = pd.DataFrame(final_rs['pr'].values, columns=['r']); df2['cat'] = 'mixed'\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "# create a bar plot or box plot\n",
    "fig, ax = plt.subplots(figsize=[2, 4])\n",
    "ax.grid(False)\n",
    "sns.barplot(x='cat', y='r', data=df, ci=68, capsize=0.3, errwidth=2, linewidth=2, errcolor='k', edgecolor='k',\n",
    "            saturation=1, order=['mixed','corr'], palette=['lightgray','tab:pink'])\n",
    "ax.set_xlim(-1, 2)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ystep = ymax - ymin\n",
    "ax.set_ylim(ymin-ystep*0.05, ymax+ystep*0.25)\n",
    "ss.mannwhitneyu(df1['r'], df2['r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d49291-2b52-4db7-9393-5a587293b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the samples\n",
    "df1 = pd.DataFrame(final_rs_intra['r'].values, columns=['r']); df1['cat'] = 'corr'\n",
    "df2 = pd.DataFrame(final_rs_intra['pr'].values, columns=['r']); df2['cat'] = 'mixed'\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "# create a bar plot or box plot\n",
    "fig, ax = plt.subplots(figsize=[2, 4])\n",
    "ax.grid(False)\n",
    "sns.barplot(x='cat', y='r', data=df, ci=68, capsize=0.3, errwidth=2, linewidth=2, errcolor='k', edgecolor='k',\n",
    "            saturation=1, order=['mixed','corr'], palette=['lightgray','tab:pink'])\n",
    "ax.set_xlim(-1, 2)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ystep = ymax - ymin\n",
    "ax.set_ylim(ymin-ystep*0.05, ymax+ystep*0.25)\n",
    "ss.mannwhitneyu(df1['r'], df2['r'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (base_py39)",
   "language": "python",
   "name": "base_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
